{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143888c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef129e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bank_churn_model.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1ad9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26edd041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9acc4f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f12b066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0        0.538    France  Female  0.324324       2  0.000000              1   \n",
       "1        0.516     Spain  Female  0.310811       1  0.334031              1   \n",
       "2        0.304    France  Female  0.324324       8  0.636357              3   \n",
       "3        0.698    France  Female  0.283784       1  0.000000              2   \n",
       "4        1.000     Spain  Female  0.337838       2  0.500246              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1         0.506735       1  \n",
       "1          0               1         0.562709       0  \n",
       "2          1               0         0.569654       1  \n",
       "3          0               0         0.469120       0  \n",
       "4          1               1         0.395400       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_scale = ['CreditScore','Age','Balance','EstimatedSalary']\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df3 =df2.copy()\n",
    "df3[columns_to_scale] = MinMaxScaler().fit_transform(df3[columns_to_scale])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49fa05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.Geography.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e9fd00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6010.576"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.CreditScore.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42314e2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography\n",
      "France     4204\n",
      "Germany    1695\n",
      "Spain      2064\n",
      "Name: Exited, dtype: int64 Geography\n",
      "France     810\n",
      "Germany    814\n",
      "Spain      413\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "churned_0 = df3[df3.Exited == 0].groupby('Geography')['Exited'].count()\n",
    "churned_1 = df3[df3.Exited == 1].groupby('Geography')['Exited'].count()\n",
    "print(churned_0,churned_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af6a82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.arange(3)\n",
    "plt.bar(x,churned_0,width=0.4,label='Not Churned')\n",
    "plt.bar(x+0.4,churned_1,width=0.4,label='Churned')\n",
    "plt.xticks(x+0.2,['France','Germany','Spain'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef516c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0        0.538  0.324324       2  0.000000              1          1   \n",
       "1        0.516  0.310811       1  0.334031              1          0   \n",
       "2        0.304  0.324324       8  0.636357              3          1   \n",
       "3        0.698  0.283784       1  0.000000              2          0   \n",
       "4        1.000  0.337838       2  0.500246              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1         0.506735       1              False   \n",
       "1               1         0.562709       0              False   \n",
       "2               0         0.569654       1              False   \n",
       "3               0         0.469120       0              False   \n",
       "4               1         0.395400       0              False   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0            False        False  \n",
       "1             True        False  \n",
       "2            False        False  \n",
       "3            False        False  \n",
       "4             True        False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.get_dummies(df3,drop_first=True)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2567a6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8562e3",
   "metadata": {},
   "source": [
    "<h3> My data set is ready,<br>\n",
    "    Let's start feeding the data to machine</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08542460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 10:52:13.713584: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-18 10:52:13.724946: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-18 10:52:13.809706: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-18 10:52:13.892461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-18 10:52:13.978747: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-18 10:52:14.000221: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-18 10:52:14.164616: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 10:52:15.944788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3be777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train,X_test,y_train,y_test,loss='binary_crossentropy',weights=-1):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(11,input_dim = 11,activation='relu'),\n",
    "        keras.layers.Dense(7,activation='relu'),\n",
    "        keras.layers.Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',loss=loss,metrics=['accuracy'])\n",
    "    \n",
    "    if weights==-1:\n",
    "        model.fit(X_train,y_train,epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train,y_train,epochs=100,weights=weights)\n",
    "    \n",
    "    print(model.evaluate(X_test,y_test))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    print(\"Classification Report is:\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a7f6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df4.drop('Exited',axis=1)\n",
    "y = df4.Exited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312ff34",
   "metadata": {},
   "source": [
    "### spliting the data into train and test\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a939f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=5,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4171bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abir/miniconda3/envs/simple_env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721278355.305844   19579 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 10:52:35.306299: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4440 - loss: 0.8121\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7987 - loss: 0.4764\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8055 - loss: 0.4587\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8127 - loss: 0.4449\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8022 - loss: 0.4513\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8115 - loss: 0.4346\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4317\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8152 - loss: 0.4284\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.4123\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8275 - loss: 0.4050\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.3878\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8224 - loss: 0.4079\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3877\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3811\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8379 - loss: 0.3793\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 0.3751\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8474 - loss: 0.3673\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3694\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8451 - loss: 0.3671\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8529 - loss: 0.3602\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3735\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8581 - loss: 0.3526\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.3530\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8470 - loss: 0.3600\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8496 - loss: 0.3645\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8504 - loss: 0.3624\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8489 - loss: 0.3576\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3531\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8561 - loss: 0.3468\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8458 - loss: 0.3692\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.3548\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.3569\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8516 - loss: 0.3609\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 0.3651\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.3548\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.3526\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8559 - loss: 0.3476\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 61ms/step - accuracy: 0.8577 - loss: 0.3488\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8532 - loss: 0.3475\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8617 - loss: 0.3415\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 0.3495\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8527 - loss: 0.3455\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8533 - loss: 0.3495\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8617 - loss: 0.3434\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 0.3358\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8522 - loss: 0.3513\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.3546\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8613 - loss: 0.3391\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8544 - loss: 0.3443\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8611 - loss: 0.3358\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8543 - loss: 0.3474\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.3497\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8642 - loss: 0.3389\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8556 - loss: 0.3494\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8591 - loss: 0.3405\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.8568 - loss: 0.3466\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 0.3461\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3457\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8573 - loss: 0.3419\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.3434\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8504 - loss: 0.3584\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8538 - loss: 0.3451\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8582 - loss: 0.3398\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8602 - loss: 0.3376\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 0.3479\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8577 - loss: 0.3453\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8627 - loss: 0.3386\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8655 - loss: 0.3338\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 89ms/step - accuracy: 0.8596 - loss: 0.3411\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8502 - loss: 0.3588\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.3466\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8633 - loss: 0.3344\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8618 - loss: 0.3367\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8571 - loss: 0.3440\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8628 - loss: 0.3394\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8526 - loss: 0.3481\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - accuracy: 0.8630 - loss: 0.3412\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8553 - loss: 0.3464\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8629 - loss: 0.3307\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8615 - loss: 0.3388\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8612 - loss: 0.3387\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8698 - loss: 0.3208\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8627 - loss: 0.3347\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8574 - loss: 0.3459\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3519\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.3406\n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 0.3484\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.3376\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 0.3397\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 99ms/step - accuracy: 0.8549 - loss: 0.3520\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8596 - loss: 0.3377\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.3534\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.3267\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8715 - loss: 0.3279\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.3378\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.3344\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3353\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8653 - loss: 0.3337\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8587 - loss: 0.3452\n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8615 - loss: 0.3392\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.3605\n",
      "[0.3583475649356842, 0.8500000238418579]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "Classification Report is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1595\n",
      "           1       0.69      0.46      0.56       405\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.78      0.71      0.73      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76c5e5",
   "metadata": {},
   "source": [
    "<h3> Under sampling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed47e094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1632, 11), (6368, 11), 1632, 6368)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exited = X_train[y_train==1]\n",
    "df_not_exited = X_train[y_train==0]\n",
    "no_df_exited = df_exited.shape[0]\n",
    "no_df_not_exited = df_not_exited.shape[0]\n",
    "\n",
    "y_exited = y_train[y_train == 1]\n",
    "y_not_exited = y_train[y_train == 0]\n",
    "\n",
    "\n",
    "df_exited.shape,df_not_exited.shape,no_df_exited,no_df_not_exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b50544a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3264, 11), (3264,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sampled = pd.concat([df_exited,df_not_exited.sample(no_df_exited)],axis=0)\n",
    "y_train_sampled = pd.concat([y_exited, y_not_exited.sample(no_df_exited)], axis=0)\n",
    "\n",
    "X_train_sampled.shape,y_train_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "718c1e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abir/miniconda3/envs/simple_env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5344 - loss: 0.6956\n",
      "Epoch 2/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 0.6672\n",
      "Epoch 3/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.6078 - loss: 0.6584\n",
      "Epoch 4/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.6651 - loss: 0.6265\n",
      "Epoch 5/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.6709 - loss: 0.6215\n",
      "Epoch 6/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6639 - loss: 0.6288\n",
      "Epoch 7/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.6581 - loss: 0.6203\n",
      "Epoch 8/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6536 - loss: 0.6160\n",
      "Epoch 9/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6822 - loss: 0.6046\n",
      "Epoch 10/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6711 - loss: 0.6074\n",
      "Epoch 11/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6779 - loss: 0.5981\n",
      "Epoch 12/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6814 - loss: 0.5922\n",
      "Epoch 13/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6900 - loss: 0.5865\n",
      "Epoch 14/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7009 - loss: 0.5945\n",
      "Epoch 15/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6923 - loss: 0.5930\n",
      "Epoch 16/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.6853 - loss: 0.5878\n",
      "Epoch 17/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6965 - loss: 0.5934\n",
      "Epoch 18/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7072 - loss: 0.5776\n",
      "Epoch 19/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7173 - loss: 0.5657\n",
      "Epoch 20/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6927 - loss: 0.5916\n",
      "Epoch 21/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.5883\n",
      "Epoch 22/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6944 - loss: 0.5899\n",
      "Epoch 23/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7018 - loss: 0.5734\n",
      "Epoch 24/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7014 - loss: 0.5712\n",
      "Epoch 25/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6938 - loss: 0.5823\n",
      "Epoch 26/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7017 - loss: 0.5847\n",
      "Epoch 27/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.5808\n",
      "Epoch 28/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.5640\n",
      "Epoch 29/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7134 - loss: 0.5679\n",
      "Epoch 30/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6954 - loss: 0.5826\n",
      "Epoch 31/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7109 - loss: 0.5599\n",
      "Epoch 32/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6941 - loss: 0.5801\n",
      "Epoch 33/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7056 - loss: 0.5680\n",
      "Epoch 34/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7036 - loss: 0.5733\n",
      "Epoch 35/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6939 - loss: 0.5772\n",
      "Epoch 36/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7167 - loss: 0.5640\n",
      "Epoch 37/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.5663\n",
      "Epoch 38/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.5593\n",
      "Epoch 39/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7115 - loss: 0.5672\n",
      "Epoch 40/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7178 - loss: 0.5574\n",
      "Epoch 41/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.5671\n",
      "Epoch 42/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7075 - loss: 0.5609\n",
      "Epoch 43/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7282 - loss: 0.5455\n",
      "Epoch 44/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5435\n",
      "Epoch 45/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7000 - loss: 0.5686\n",
      "Epoch 46/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.5577\n",
      "Epoch 47/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7104 - loss: 0.5553\n",
      "Epoch 48/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7117 - loss: 0.5584\n",
      "Epoch 49/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7154 - loss: 0.5469\n",
      "Epoch 50/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.5478\n",
      "Epoch 51/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.5594\n",
      "Epoch 52/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7007 - loss: 0.5614\n",
      "Epoch 53/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7281 - loss: 0.5425\n",
      "Epoch 54/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7202 - loss: 0.5411\n",
      "Epoch 55/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7219 - loss: 0.5512\n",
      "Epoch 56/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7187 - loss: 0.5501\n",
      "Epoch 57/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7028 - loss: 0.5487\n",
      "Epoch 58/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7202 - loss: 0.5468\n",
      "Epoch 59/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7140 - loss: 0.5480\n",
      "Epoch 60/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7326 - loss: 0.5329\n",
      "Epoch 61/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7024 - loss: 0.5587\n",
      "Epoch 62/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7076 - loss: 0.5607\n",
      "Epoch 63/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7147 - loss: 0.5463\n",
      "Epoch 64/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7091 - loss: 0.5433\n",
      "Epoch 65/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7140 - loss: 0.5488\n",
      "Epoch 66/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7021 - loss: 0.5621\n",
      "Epoch 67/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7075 - loss: 0.5527\n",
      "Epoch 68/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7241 - loss: 0.5387\n",
      "Epoch 69/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7229 - loss: 0.5454\n",
      "Epoch 70/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7247 - loss: 0.5424\n",
      "Epoch 71/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.5440\n",
      "Epoch 72/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5345\n",
      "Epoch 73/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7101 - loss: 0.5543\n",
      "Epoch 74/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7118 - loss: 0.5486\n",
      "Epoch 75/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7140 - loss: 0.5468\n",
      "Epoch 76/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7296 - loss: 0.5269\n",
      "Epoch 77/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7225 - loss: 0.5304\n",
      "Epoch 78/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7124 - loss: 0.5463\n",
      "Epoch 79/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7274 - loss: 0.5351\n",
      "Epoch 80/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7241 - loss: 0.5362\n",
      "Epoch 81/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7049 - loss: 0.5588\n",
      "Epoch 82/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7322 - loss: 0.5310\n",
      "Epoch 83/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7303 - loss: 0.5329\n",
      "Epoch 84/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7270 - loss: 0.5325\n",
      "Epoch 85/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7267 - loss: 0.5327\n",
      "Epoch 86/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7446 - loss: 0.5214\n",
      "Epoch 87/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7268 - loss: 0.5284\n",
      "Epoch 88/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7505 - loss: 0.5165\n",
      "Epoch 89/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7418 - loss: 0.5138\n",
      "Epoch 90/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7413 - loss: 0.5198\n",
      "Epoch 91/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7586 - loss: 0.4984\n",
      "Epoch 92/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7518 - loss: 0.5089\n",
      "Epoch 93/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7482 - loss: 0.5113\n",
      "Epoch 94/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7522 - loss: 0.5039\n",
      "Epoch 95/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.5136\n",
      "Epoch 96/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7580 - loss: 0.4974\n",
      "Epoch 97/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7566 - loss: 0.4961\n",
      "Epoch 98/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7541 - loss: 0.5040\n",
      "Epoch 99/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.4975\n",
      "Epoch 100/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7651 - loss: 0.4837\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7604 - loss: 0.4842\n",
      "[0.4769279658794403, 0.7645000219345093]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Classification Report is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84      1595\n",
      "           1       0.45      0.67      0.53       405\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.67      0.73      0.69      2000\n",
      "weighted avg       0.81      0.76      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X_train,X_test,y_train,y_test = train_test_split(X.drop('Exited',axis=1),X.Exited,random_state=5,test_size=0.2)\n",
    "y_preds = ANN(X_train_sampled,X_test,y_train_sampled,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27142899",
   "metadata": {},
   "source": [
    "<h3>method2: Oversampling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b42d62eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12736, 11), (12736,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sampled = pd.concat([df_exited.sample(no_df_not_exited,replace=True,),df_not_exited],axis=0)\n",
    "y_train_sampled = pd.concat([y_exited.sample(no_df_not_exited,replace=True), y_not_exited], axis=0)\n",
    "X_train_sampled.shape,y_train_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "548ab8fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abir/miniconda3/envs/simple_env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5066 - loss: 0.7943\n",
      "Epoch 2/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5286 - loss: 0.6920\n",
      "Epoch 3/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6361 - loss: 0.6608\n",
      "Epoch 4/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6904 - loss: 0.6258\n",
      "Epoch 5/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7038 - loss: 0.6002\n",
      "Epoch 6/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7149 - loss: 0.5777\n",
      "Epoch 7/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7196 - loss: 0.5640\n",
      "Epoch 8/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7393 - loss: 0.5352\n",
      "Epoch 9/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7436 - loss: 0.5278\n",
      "Epoch 10/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7416 - loss: 0.5276\n",
      "Epoch 11/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.5201\n",
      "Epoch 12/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5170\n",
      "Epoch 13/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7508 - loss: 0.5170\n",
      "Epoch 14/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7529 - loss: 0.5090\n",
      "Epoch 15/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7607 - loss: 0.5003\n",
      "Epoch 16/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7633 - loss: 0.4952\n",
      "Epoch 17/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7564 - loss: 0.5049\n",
      "Epoch 18/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7609 - loss: 0.4939\n",
      "Epoch 19/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7635 - loss: 0.4934\n",
      "Epoch 20/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7627 - loss: 0.4965\n",
      "Epoch 21/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7681 - loss: 0.4918\n",
      "Epoch 22/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7652 - loss: 0.4875\n",
      "Epoch 23/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7614 - loss: 0.4895\n",
      "Epoch 24/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7653 - loss: 0.4902\n",
      "Epoch 25/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7679 - loss: 0.4870\n",
      "Epoch 26/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7621 - loss: 0.4947\n",
      "Epoch 27/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7613 - loss: 0.4911\n",
      "Epoch 28/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7707 - loss: 0.4837\n",
      "Epoch 29/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.4828\n",
      "Epoch 30/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 0.4875\n",
      "Epoch 31/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7702 - loss: 0.4810\n",
      "Epoch 32/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7631 - loss: 0.4871\n",
      "Epoch 33/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 0.4740\n",
      "Epoch 34/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7662 - loss: 0.4851\n",
      "Epoch 35/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7670 - loss: 0.4828\n",
      "Epoch 36/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7691 - loss: 0.4801\n",
      "Epoch 37/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7678 - loss: 0.4819\n",
      "Epoch 38/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 0.4722\n",
      "Epoch 39/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4747\n",
      "Epoch 40/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7758 - loss: 0.4726\n",
      "Epoch 41/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7712 - loss: 0.4805\n",
      "Epoch 42/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.4790\n",
      "Epoch 43/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.4806\n",
      "Epoch 44/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.4818\n",
      "Epoch 45/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7627 - loss: 0.4839\n",
      "Epoch 46/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.4814\n",
      "Epoch 47/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7688 - loss: 0.4784\n",
      "Epoch 48/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7668 - loss: 0.4800\n",
      "Epoch 49/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.7698 - loss: 0.4766\n",
      "Epoch 50/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.4771\n",
      "Epoch 51/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7679 - loss: 0.4779\n",
      "Epoch 52/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7668 - loss: 0.4722\n",
      "Epoch 53/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7696 - loss: 0.4742\n",
      "Epoch 54/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7680 - loss: 0.4801\n",
      "Epoch 55/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 0.4882\n",
      "Epoch 56/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7677 - loss: 0.4781\n",
      "Epoch 57/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.4814\n",
      "Epoch 58/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.4713\n",
      "Epoch 59/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4748\n",
      "Epoch 60/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.4794\n",
      "Epoch 61/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.4745\n",
      "Epoch 62/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7753 - loss: 0.4710\n",
      "Epoch 63/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7724 - loss: 0.4705\n",
      "Epoch 64/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7664 - loss: 0.4759\n",
      "Epoch 65/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 55ms/step - accuracy: 0.7735 - loss: 0.4738\n",
      "Epoch 66/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7692 - loss: 0.4683\n",
      "Epoch 67/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7705 - loss: 0.4700\n",
      "Epoch 68/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7753 - loss: 0.4679\n",
      "Epoch 69/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7723 - loss: 0.4711\n",
      "Epoch 70/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7698 - loss: 0.4717\n",
      "Epoch 71/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.7771 - loss: 0.4612\n",
      "Epoch 72/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7657 - loss: 0.4697\n",
      "Epoch 73/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7734 - loss: 0.4591\n",
      "Epoch 74/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7782 - loss: 0.4609\n",
      "Epoch 75/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7692 - loss: 0.4695\n",
      "Epoch 76/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.7734 - loss: 0.4680\n",
      "Epoch 77/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.7730 - loss: 0.4645\n",
      "Epoch 78/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7753 - loss: 0.4623\n",
      "Epoch 79/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7636 - loss: 0.4745\n",
      "Epoch 80/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7835 - loss: 0.4547\n",
      "Epoch 81/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7795 - loss: 0.4612\n",
      "Epoch 82/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7780 - loss: 0.4550\n",
      "Epoch 83/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7790 - loss: 0.4597\n",
      "Epoch 84/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 64ms/step - accuracy: 0.7768 - loss: 0.4589\n",
      "Epoch 85/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7756 - loss: 0.4627\n",
      "Epoch 86/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7759 - loss: 0.4664\n",
      "Epoch 87/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7783 - loss: 0.4575\n",
      "Epoch 88/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7789 - loss: 0.4579\n",
      "Epoch 89/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7847 - loss: 0.4544\n",
      "Epoch 90/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 53ms/step - accuracy: 0.7822 - loss: 0.4574\n",
      "Epoch 91/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.4607\n",
      "Epoch 92/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.4575\n",
      "Epoch 93/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.4557\n",
      "Epoch 94/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7712 - loss: 0.4679\n",
      "Epoch 95/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.7751 - loss: 0.4572\n",
      "Epoch 96/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 67ms/step - accuracy: 0.7813 - loss: 0.4605\n",
      "Epoch 97/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7807 - loss: 0.4500\n",
      "Epoch 98/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7839 - loss: 0.4538\n",
      "Epoch 99/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7801 - loss: 0.4566\n",
      "Epoch 100/100\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7754 - loss: 0.4583\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7402 - loss: 0.5372\n",
      "[0.5249124765396118, 0.7384999990463257]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Classification Report is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.73      0.82      1595\n",
      "           1       0.42      0.78      0.55       405\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.68      0.75      0.68      2000\n",
      "weighted avg       0.83      0.74      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train_sampled,X_test,y_train_sampled,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32362da3",
   "metadata": {},
   "source": [
    "<h3> method 3: smote</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18a5daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6368\n",
       "1    6368\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_train_sm,y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "y_train_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4209aab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abir/miniconda3/envs/simple_env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.5266 - loss: 0.7397\n",
      "Epoch 2/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6585 - loss: 0.6241\n",
      "Epoch 3/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6869 - loss: 0.5903\n",
      "Epoch 4/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7103 - loss: 0.5684\n",
      "Epoch 5/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 75ms/step - accuracy: 0.7170 - loss: 0.5540\n",
      "Epoch 6/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7372 - loss: 0.5358\n",
      "Epoch 7/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7404 - loss: 0.5262\n",
      "Epoch 8/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.5157\n",
      "Epoch 9/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.5057\n",
      "Epoch 10/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7477 - loss: 0.5087\n",
      "Epoch 11/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7585 - loss: 0.4955\n",
      "Epoch 12/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7656 - loss: 0.4837\n",
      "Epoch 13/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.4659\n",
      "Epoch 14/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7741 - loss: 0.4699\n",
      "Epoch 15/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7825 - loss: 0.4652\n",
      "Epoch 16/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7847 - loss: 0.4652\n",
      "Epoch 17/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7804 - loss: 0.4570\n",
      "Epoch 18/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - accuracy: 0.7837 - loss: 0.4571\n",
      "Epoch 19/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.4513\n",
      "Epoch 20/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.4437\n",
      "Epoch 21/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7904 - loss: 0.4459\n",
      "Epoch 22/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4412\n",
      "Epoch 23/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7889 - loss: 0.4450\n",
      "Epoch 24/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7923 - loss: 0.4426\n",
      "Epoch 25/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.4406\n",
      "Epoch 26/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.4333\n",
      "Epoch 27/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8028 - loss: 0.4330\n",
      "Epoch 28/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4261\n",
      "Epoch 29/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - accuracy: 0.7982 - loss: 0.4339\n",
      "Epoch 30/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.7971 - loss: 0.4302\n",
      "Epoch 31/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8020 - loss: 0.4319\n",
      "Epoch 32/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7996 - loss: 0.4295\n",
      "Epoch 33/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8015 - loss: 0.4308\n",
      "Epoch 34/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.4293\n",
      "Epoch 35/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4219\n",
      "Epoch 36/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.4263\n",
      "Epoch 37/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8031 - loss: 0.4284\n",
      "Epoch 38/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7975 - loss: 0.4293\n",
      "Epoch 39/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7959 - loss: 0.4336\n",
      "Epoch 40/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 0.8018 - loss: 0.4216\n",
      "Epoch 41/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.4207\n",
      "Epoch 42/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4311\n",
      "Epoch 43/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.4297\n",
      "Epoch 44/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4136\n",
      "Epoch 45/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4164\n",
      "Epoch 46/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.4308\n",
      "Epoch 47/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.8056 - loss: 0.4156\n",
      "Epoch 48/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.8084 - loss: 0.4198\n",
      "Epoch 49/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.4235\n",
      "Epoch 50/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8018 - loss: 0.4221\n",
      "Epoch 51/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8073 - loss: 0.4195\n",
      "Epoch 52/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.4184\n",
      "Epoch 53/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8045 - loss: 0.4217\n",
      "Epoch 54/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.4244\n",
      "Epoch 55/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8013 - loss: 0.4254\n",
      "Epoch 56/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.4169\n",
      "Epoch 57/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - accuracy: 0.8036 - loss: 0.4246\n",
      "Epoch 58/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - accuracy: 0.8021 - loss: 0.4277\n",
      "Epoch 59/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8092 - loss: 0.4141\n",
      "Epoch 60/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8047 - loss: 0.4103\n",
      "Epoch 61/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.4114\n",
      "Epoch 62/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4119\n",
      "Epoch 63/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8107 - loss: 0.4173\n",
      "Epoch 64/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4142\n",
      "Epoch 65/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4138\n",
      "Epoch 66/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - accuracy: 0.8032 - loss: 0.4205\n",
      "Epoch 67/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8151 - loss: 0.4049\n",
      "Epoch 68/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8160 - loss: 0.4032\n",
      "Epoch 69/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8033 - loss: 0.4164\n",
      "Epoch 70/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4238\n",
      "Epoch 71/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8090 - loss: 0.4143\n",
      "Epoch 72/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.4192\n",
      "Epoch 73/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4099\n",
      "Epoch 74/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8107 - loss: 0.4167\n",
      "Epoch 75/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.4199\n",
      "Epoch 76/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.4130\n",
      "Epoch 77/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.4092\n",
      "Epoch 78/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8035 - loss: 0.4219\n",
      "Epoch 79/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.8127 - loss: 0.4141\n",
      "Epoch 80/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8034 - loss: 0.4199\n",
      "Epoch 81/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8085 - loss: 0.4187\n",
      "Epoch 82/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 0.4140\n",
      "Epoch 83/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.4099\n",
      "Epoch 84/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8150 - loss: 0.4055\n",
      "Epoch 85/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4130\n",
      "Epoch 86/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4211\n",
      "Epoch 87/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.4204\n",
      "Epoch 88/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8097 - loss: 0.4162\n",
      "Epoch 89/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.4141\n",
      "Epoch 90/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8051 - loss: 0.4202\n",
      "Epoch 91/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4068\n",
      "Epoch 92/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4069\n",
      "Epoch 93/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8089 - loss: 0.4121\n",
      "Epoch 94/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.4123\n",
      "Epoch 95/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.4118\n",
      "Epoch 96/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.4062\n",
      "Epoch 97/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8135 - loss: 0.4089\n",
      "Epoch 98/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4155\n",
      "Epoch 99/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.4138\n",
      "Epoch 100/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8089 - loss: 0.4116\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8003 - loss: 0.4387\n",
      "[0.41430726647377014, 0.8131868243217468]\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Classification Report is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1295\n",
      "           1       0.82      0.80      0.81      1253\n",
      "\n",
      "    accuracy                           0.81      2548\n",
      "   macro avg       0.81      0.81      0.81      2548\n",
      "weighted avg       0.81      0.81      0.81      2548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_train_sm,y_train_sm,random_state=5,test_size=0.2)\n",
    "y_preds = ANN(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84949c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
